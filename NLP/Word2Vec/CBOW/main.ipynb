{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "import pandas as pd\n",
    "from torch.nn import functional as F\n",
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "CONTEXT_SIZE = 3\n",
    "DATA_PATH = '../business'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File Name</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>289.txt</td>\n",
       "      <td>UK economy facing 'major risks'\\n\\nThe UK manu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>504.txt</td>\n",
       "      <td>Aids and climate top Davos agenda\\n\\nClimate c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>262.txt</td>\n",
       "      <td>Asian quake hits European shares\\n\\nShares in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>276.txt</td>\n",
       "      <td>India power shares jump on debut\\n\\nShares in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>510.txt</td>\n",
       "      <td>Lacroix label bought by US firm\\n\\nLuxury good...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  File Name                                               Text\n",
       "0   289.txt  UK economy facing 'major risks'\\n\\nThe UK manu...\n",
       "1   504.txt  Aids and climate top Davos agenda\\n\\nClimate c...\n",
       "2   262.txt  Asian quake hits European shares\\n\\nShares in ...\n",
       "3   276.txt  India power shares jump on debut\\n\\nShares in ...\n",
       "4   510.txt  Lacroix label bought by US firm\\n\\nLuxury good..."
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_list = [f for f in os.listdir(DATA_PATH) if f.endswith('.txt')]\n",
    "data = {'File Name': [], 'Text': []}\n",
    "\n",
    "for file_name in file_list:\n",
    "    file_path = os.path.join(DATA_PATH, file_name)\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "        data['File Name'].append(file_name)\n",
    "        data['Text'].append(content)\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the first line (title) from the 'Text' column\n",
    "test_df = df.copy()\n",
    "test_df['Text'] = test_df['Text'].str.split('\\n', 1).str[1]\n",
    "\n",
    "# Remove all white spaces from the 'Text' column\n",
    "test_df['Text'] = test_df['Text'].str.replace(r'\\n', '', regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(data_path):\n",
    "    file_list = [f for f in os.listdir(DATA_PATH) if f.endswith('.txt')]\n",
    "    data = {'File Name': [], 'Text': []}\n",
    "\n",
    "    for file_name in file_list:\n",
    "        file_path = os.path.join(DATA_PATH, file_name)\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            content = file.read()\n",
    "            data['File Name'].append(file_name)\n",
    "            data['Text'].append(content)\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Remove the first line (title) from the 'Text' column\n",
    "    df['Text'] = df['Text'].str.split('\\n', 1).str[1]\n",
    "    \n",
    "    # Remove all white spaces from the 'Text' column\n",
    "    df['Text'] = df['Text'].str.replace(r'\\n', '', regex=True)\n",
    "\n",
    "    return df[\"Text\"]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>windows</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The UK manufacturing will continue to</td>\n",
       "      <td>sector</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UK manufacturing sector continue to face</td>\n",
       "      <td>will</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>manufacturing sector will to face \"serious</td>\n",
       "      <td>continue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sector will continue face \"serious challenges\"</td>\n",
       "      <td>to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>will continue to \"serious challenges\" over</td>\n",
       "      <td>face</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          windows    labels\n",
       "0           The UK manufacturing will continue to    sector\n",
       "1        UK manufacturing sector continue to face      will\n",
       "2      manufacturing sector will to face \"serious  continue\n",
       "3  sector will continue face \"serious challenges\"        to\n",
       "4      will continue to \"serious challenges\" over      face"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_windows_dataframe(data, context_size):\n",
    "    all_windows_str = []  # Modified to store windows as strings\n",
    "    all_labels = []\n",
    "\n",
    "    for index, row in data.iterrows():\n",
    "        input_sequence = row[\"Text\"].split()\n",
    "\n",
    "        num_windows = len(input_sequence) - 2 * context_size\n",
    "\n",
    "        for i in range(num_windows):\n",
    "            window = input_sequence[i: i + context_size] + input_sequence[i + context_size + 1: i + 2 * context_size + 1]\n",
    "            window_str = \" \".join(window)  # Convert the window list to a string\n",
    "            label = input_sequence[i + context_size]\n",
    "            all_windows_str.append(window_str)  # Append the window string\n",
    "            all_labels.append(label)\n",
    "\n",
    "    # Create a pandas DataFrame from the lists\n",
    "    windows_df = pd.DataFrame({\n",
    "        'windows': all_windows_str,  # Use the modified list containing window strings\n",
    "        'labels': all_labels\n",
    "    })\n",
    "\n",
    "    return windows_df\n",
    "\n",
    "# Assuming you have a DataFrame named 'test_df' with a column named 'Text'\n",
    "windows_dataframe = create_windows_dataframe(test_df, CONTEXT_SIZE)\n",
    "\n",
    "windows_dataframe.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and val\n",
    "X, y = windows_dataframe[\"windows\"], windows_dataframe[\"labels\"]\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, train_size=0.8)\n",
    "\n",
    "X_train = X_train.to_list()\n",
    "X_val = X_val.to_list()\n",
    "y_train = y_train.to_list()\n",
    "y_val = y_val.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Text Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, windows, labels, tokenizer):\n",
    "        self.windows = windows\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.windows)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        window = self.windows[index]\n",
    "        label = self.labels[index]\n",
    "\n",
    "        # Tokenize the text\n",
    "        tokenized_window = self.tokenizer(window, max_length=10, truncation=True, padding=\"max_length\", add_special_tokens=False, return_tensors=\"pt\")[\"input_ids\"][0]\n",
    "        tokenized_label = self.tokenizer(label, max_length=3, truncation=True, padding=\"max_length\", add_special_tokens=False, return_tensors=\"pt\")[\"input_ids\"][0]\n",
    "\n",
    "        return {\n",
    "            \"window\": tokenized_window,\n",
    "            \"label\": tokenized_label\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TextDataset(X_train, y_train, tokenizer)\n",
    "val_ds = TextDataset(X_val, y_val, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
