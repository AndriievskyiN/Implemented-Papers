{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "import pandas as pd\n",
    "from torch.nn import functional as F\n",
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "CONTEXT_SIZE = 3\n",
    "DATA_PATH = '../business'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = [f for f in os.listdir(DATA_PATH) if f.endswith('.txt')]\n",
    "data = {'File Name': [], 'Text': []}\n",
    "\n",
    "for file_name in file_list:\n",
    "    file_path = os.path.join(DATA_PATH, file_name)\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "        data['File Name'].append(file_name)\n",
    "        data['Text'].append(content)\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Remove the first line (title) from the 'Text' column\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m test_df \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m      3\u001b[0m test_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mText\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m test_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mText\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mstr[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Remove all white spaces from the 'Text' column\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# Remove the first line (title) from the 'Text' column\n",
    "test_df = df.copy()\n",
    "test_df['Text'] = test_df['Text'].str.split('\\n', 1).str[1]\n",
    "\n",
    "# Remove all white spaces from the 'Text' column\n",
    "test_df['Text'] = test_df['Text'].str.replace(r'\\n', '', regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(data_path):\n",
    "    file_list = [f for f in os.listdir(DATA_PATH) if f.endswith('.txt')]\n",
    "    data = {'File Name': [], 'Text': []}\n",
    "\n",
    "    for file_name in file_list:\n",
    "        file_path = os.path.join(DATA_PATH, file_name)\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            content = file.read()\n",
    "            data['File Name'].append(file_name)\n",
    "            data['Text'].append(content)\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Remove the first line (title) from the 'Text' column\n",
    "    df['Text'] = df['Text'].str.split('\\n', 1).str[1]\n",
    "    \n",
    "    # Remove all white spaces from the 'Text' column\n",
    "    df['Text'] = df['Text'].str.replace(r'\\n', '', regex=True)\n",
    "\n",
    "    return df[\"Text\"]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>windows</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[The, UK, manufacturing, will, continue, to]</td>\n",
       "      <td>sector</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[UK, manufacturing, sector, continue, to, face]</td>\n",
       "      <td>will</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[manufacturing, sector, will, to, face, \"serious]</td>\n",
       "      <td>continue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[sector, will, continue, face, \"serious, chall...</td>\n",
       "      <td>to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[will, continue, to, \"serious, challenges\", over]</td>\n",
       "      <td>face</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             windows    labels\n",
       "0       [The, UK, manufacturing, will, continue, to]    sector\n",
       "1    [UK, manufacturing, sector, continue, to, face]      will\n",
       "2  [manufacturing, sector, will, to, face, \"serious]  continue\n",
       "3  [sector, will, continue, face, \"serious, chall...        to\n",
       "4  [will, continue, to, \"serious, challenges\", over]      face"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_windows_dataframe(data, context_size):\n",
    "    all_windows = []\n",
    "    all_labels = []\n",
    "\n",
    "    for index, row in data.iterrows():\n",
    "        input_sequence = row[\"Text\"].split()\n",
    "\n",
    "        num_windows = len(input_sequence) - 2 * context_size\n",
    "\n",
    "        for i in range(num_windows):\n",
    "            window = input_sequence[i: i + context_size] + input_sequence[i + context_size + 1: i + 2 * context_size + 1]\n",
    "            label = input_sequence[i + context_size]\n",
    "            all_windows.append(window)\n",
    "            all_labels.append(label)\n",
    "\n",
    "    # Create a pandas DataFrame from the lists\n",
    "    windows_df = pd.DataFrame({\n",
    "        'windows': all_windows,\n",
    "        'labels': all_labels\n",
    "    })\n",
    "\n",
    "    return windows_df\n",
    "\n",
    "# Assuming you have a DataFrame named 'test_df' with a column named 'Text'\n",
    "windows_dataframe = create_windows_dataframe(test_df, CONTEXT_SIZE)\n",
    "\n",
    "windows_dataframe.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and val\n",
    "X, y = windows_dataframe[\"windows\"], windows_dataframe[\"labels\"]\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, train_size=0.8)\n",
    "\n",
    "X_train = X_train.to_list()\n",
    "X_val = X_val.to_list()\n",
    "y_train = y_train.to_list()\n",
    "y_val = y_val.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Text Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, windows, labels, tokenizer):\n",
    "        self.windows = windows\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.windows)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        window = self.windows[index]\n",
    "        label = self.labels[index]\n",
    "\n",
    "        # Tokenize the text\n",
    "        tokenized_window = self.tokenizer(window, truncation=False, padding=False, add_special_tokens=False, return_tensors=\"pt\")[\"input_ids\"]\n",
    "        tokenized_label = self.tokenizer(label, truncation=False, padding=False, add_special_tokens=False, return_tensors=\"pt\")[\"input_ids\"]\n",
    "\n",
    "        return {\n",
    "            \"window\": tokenized_window,\n",
    "            \"label\": tokenized_label\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TextDataset(X_train, y_train, tokenizer)\n",
    "val_ds = TextDataset(X_val, y_val, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
